좋은 아이디어고, **“AI 퍼실리테이터가 참여하는 이벤트 스토밍 전용 화상회의”**라는 점에서 기존 Zoom·Miro·FigJam과 **명확히 다른 카테고리**입니다.
아래는 **구현을 바로 시작할 수 있을 정도의 수준**으로 정리한 **PRD (Product Requirements Document)** 초안입니다.

---

# 📘 PRD

## 제품명(가칭)

**AI Event Storming Facilitator (AESF)**
*웹RTC 기반 실시간 화상회의 + AI 퍼실리테이션 이벤트 스토밍*

---

## 1. 제품 비전 & 목적

### 🎯 목적

* **이벤트 스토밍을 “혼자 잘하는 사람 없이도” 수행 가능하게 만든다**
* 퍼실리테이터의 숙련도 의존성을 제거
* **1시간 이내**에 의미 있는 도메인 이벤트 맵을 완성

### 💡 핵심 차별점

| 기존 도구        | 본 제품                |
| ------------ | ------------------- |
| 화상회의 + 화이트보드 | **이벤트 스토밍 전용 플로우**  |
| 인간 퍼실리테이터 필요 | **AI 퍼실리테이터 상시 개입** |
| 규칙 위반 방치     | **실시간 교정 & 교육**     |
| 사후 정리 필요     | **구조화된 그래프 결과물**    |

---

## 2. 주요 사용자 (Personas)

### 1️⃣ 참가자 (Domain Expert / Developer)

* 이벤트 스토밍 초보 ~ 중급
* “이게 이벤트 맞나요?”를 자주 질문
* 규칙을 실시간으로 배우고 싶음

### 2️⃣ AI 퍼실리테이터 (시스템 사용자)

* 항상 회의에 **한 명의 참여자**로 존재
* 음성 + 스티커 변화 모두 인지
* 규칙 위반 시 개입

---

## 3. 세션 전체 흐름 (1시간 기준)

### ⏱️ 전체 타임라인

1. **오리엔테이션 (5분)**
2. **이벤트 도출 (10분)** ← 핵심
3. **이벤트 정제 & 교정 (15분)**
4. **커맨드 / 정책 / 외부시스템 배치 (15분)**
5. **타임라인 정렬 & 요약 (10분)**
6. **결과 요약 & 종료 (5분)**

---

## 4. 핵심 기능 요구사항 (Functional Requirements)

---

### 4.1 화상회의 (WebRTC)

* 브라우저 기반 화상회의
* 화면 공유 / 음소거 / 채팅
* **AI 퍼실리테이터도 동일한 참여자**

**기술 기반**

* WebRTC
* TURN/STUN 기반 NAT 통과

---

### 4.2 실시간 음성 인식 & 질문 감지

#### 요구사항

* 참가자의 음성을 실시간으로 텍스트 변환
* 다음 유형 자동 감지:

  * ❓ “이벤트가 뭐죠?”
  * ❓ “이건 커맨드 아닌가요?”
  * ❓ “이렇게 써도 되나요?”

#### 기술

* OpenAI Whisper
* 발화 → 스트리밍 텍스트 → AI 판단

---

### 4.3 이벤트 스토밍 캔버스 (동시 편집)

#### 스티커 유형

* Event (과거형)
* Command
* Policy
* Read Model
* External System

#### 기능

* 드래그 & 드롭
* 위치 이동
* 연결선 생성
* 다중 사용자 **동시 편집**

---

### 4.4 그래프 기반 스티커 저장소

#### 데이터 모델

* 모든 스티커 = Node
* 연결 = Relationship
* 속성:

  * id
  * type
  * text
  * author
  * timestamp
  * position (x, y)

#### 기술

* Neo4j

---

### 4.5 그래프 변경 이벤트 스트리밍

#### 요구사항

* 스티커 **추가 / 수정 / 삭제 / 연결**
* 실시간으로 AI에게 전달

#### 구현 전략

* Neo4j 직접 이벤트 푸시는 제한적 → **중간 Event Layer**

  * API 서버가 모든 변경을 수신
  * 변경 사항을 Event Stream으로 발행

```text
UI Action (vue3)
 → API Server
   → Neo4j write
   → Event Stream (WebSocket)
     → AI Context Feed
```

---

### 4.6 AI 퍼실리테이터 행동 규칙

#### AI의 주요 역할

##### 1️⃣ 이벤트 규칙 검증

* 과거형인가?
* “명확히 발생한 사실”인가?
* 커맨드/행위가 섞이지 않았는가?

👉 예시 개입:

> “이 스티커는 ‘주문을 생성한다’라서 커맨드에 가깝습니다.
> 이벤트라면 ‘주문이 생성되었다’가 좋아요.”

---

##### 2️⃣ 세션 타이밍 관리

* “지금은 이벤트만 붙이는 시간입니다”
* “아직 커맨드는 붙이지 않습니다”

---

##### 3️⃣ 구조적 교정

* 이벤트 순서가 섞였을 때
* 이벤트가 중복될 때
* 너무 추상적일 때

---

##### 4️⃣ 교육용 설명

* 이벤트 vs 커맨드
* 정책의 위치
* 외부 시스템의 역할

---

### 4.7 AI 아키텍처

#### 오케스트레이션

* LangChain / LangGraph


#### 실시간 대화

* OpenAI Realtime API

#### 컨텍스트 입력

* 최근 음성 질문 요약
* 최근 그래프 변경 diff
* 현재 세션 단계

---

## 5. AI 판단 로직 (개념)

```text
[Audio Stream]
   ↓
Whisper → Text
   ↓
Intent Detection
   ↓
Context Builder
   - Recent Graph Diff
   - Session Phase
   ↓
LLM 판단
   ↓
행동 결정
   - 설명
   - 교정
   - 질문
```

---

## 6. 비기능 요구사항 (NFR)

| 항목  | 요구           |
| --- | ------------ |
| 지연  | 음성→응답 1초 이내  |
| 동시성 | 10~20명 동시 편집 |
| 신뢰성 | 네트워크 끊겨도 재연결 |
| 확장성 | 세션 단위 독립     |

---

## 7. 성공 지표 (Success Metrics)

* 1시간 내 **이벤트 타임라인 완성률**
* AI 개입 후 이벤트 수정 비율
* “이벤트/커맨드 헷갈림” 질문 감소
* 세션 종료 후 **아키텍처 활용 가능성**

---

## 8. 향후 확장 (Out of Scope, v2)

* Aggregate 자동 추론
* Bounded Context 제안
* 코드 스켈레톤 생성
* 세션 리플레이 & 교육 콘텐츠화

---

## 9. 이 제품의 본질적인 포지션

> ❌ “Zoom + Whiteboard”
> ✅ **“AI가 진행하는 이벤트 스토밍 워크숍”**

이건 **도구가 아니라 ‘퍼실리테이션을 제품화’한 것**입니다.

